---
title: "Provenance, Error and Uncertainty "
excerpt_separator: "<!--more-->"
categories:
  - Blog
tags:
  - Provenance
  - Error
  - Uncertainty
  - Replication
  - Reproduction
---

[Malcomb et al (2014)]( https://www.sciencedirect.com/science/article/abs/pii/S0143622814000058?via%3Dihub) seeks to examine drivers of vulnerability at the household level to assess which parts of Malawi are most susceptible to climate vulnerability. This work is undertaken to determine where development solutions should be directed to target the most exposed households. Using a multi-scale and multi-indicator methodology, Malcomb et al (2014) seeks to bypass issues with vulnerability research that arise from utilizing global metrics over large spatiotemporal regions by focusing their analysis on one country: Malawi. In addition, Malcomb et al (2014) uses place-specific vulnerability indicators through a comprehensive literature review gathered in tandem with a series of expert interviews. Furthermore, through a place-based analytical approach, “expert opinion formed the basis of selecting the most important indicators and weighting them appropriately in this research” to ensure that the model was locally relevant (Malcomb, 2014, pg. 22).

Moreover, one of the main goals of Malcomb et al (2014) analysis was to conduct a study that addressed critiques of prior vulnerability analysis by using “locally derived indicators and granular data in a transparent and easily replicable methodology” (Malcomb, 2014, pg. 19). However, as Longley (2008) describes, there are three filters that can distort the way in which the complexity of the real world is “conceived, measured and represented, and analyzed in a cumulative way” [(Longley, 2008, figure 6.1)](https://www.geos.ed.ac.uk/~gisteac/gis_book_abridged/files/00_fm.pdf). First, there can be differences in researchers’ conceptions of the real world, which can be followed by differences in measures and representations of data, leading to variations in analysis.  

These differences are especially likely to arise in a vulnerability analysis such as Malcomb et al (2014), since data is derived from numerous data sources and there may be inconsistencies in data collection methods or quality of data in the model, particularly over long temporal spans. Additionally, uncertainty arises in model conceptualization and parameterization. For instance, Malcomb et al’s (2014) model uses expert interviews to form the basis of selecting and weighting vulnerability indicators in Malawi. While this methodology allows for a compilation of locally relevant indices, the indicator selection process is not easily replicable by subsequent researchers seeking to replicate the methods unless the same weights are utilized. In sum, there appear to be tradeoffs between using easily replicable and reproducible methods that can be used to time and again produce the same result and implementing place-specific weighting of indicators based on qualitative interviews.

In conducting research, geographers often rely on using data collected and compiled by other sources in analyses. Furthermore, geographers have an ethical responsibility to provide clear documentation of the data sources and data cleaning and analysis workflows to facilitate straightforward replication and reproduction. These steps can assist in minimizing uncertainty in conclusions. Furthermore, it is important to document the provenance of data used in GIScience including data sources and any potential biases or limitations data sources may have. Detailed documentation can assist in accounting and documenting uncertainty in methods, data, investigator subjectivity, indicator measurement, analysis, interpretation, and validation.


Longley, P. A. (2008). Analysis using geographic information systems. Handbook of Research Methods and Applications in Economic Geography, 119.

Malcomb, D. W., Weaver, E. A., & Krakowka, A. R. (2014). Vulnerability modeling for sub-Saharan Africa: An operationalized approach in Malawi. Applied geography, 48, 17-30.
